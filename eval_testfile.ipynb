{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c952fe75-8baa-49ae-b54f-7402ffa7ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from medpy.metric.binary import assd,dc\n",
    "from datetime import datetime\n",
    "import scipy.io as scio\n",
    "import os.path as osp\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import scipy.ndimage as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da228cdf-0d40-4054-b4e5-e5087e1a181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seg_map_sequence(label_mask, dataset='pascal'):\n",
    "    rgb_mask = decode_segmap(label_mask, dataset)\n",
    "    rgb_masks = np.array(rgb_mask)\n",
    "    return rgb_masks\n",
    "\n",
    "def get_cityscapes_labels():\n",
    "    return np.array([\n",
    "        # [  0,   0,   0],\n",
    "        [128, 64, 128],\n",
    "        [244, 35, 232],\n",
    "        [70, 70, 70],\n",
    "        [102, 102, 156],\n",
    "        [190, 153, 153],\n",
    "        [153, 153, 153],\n",
    "        [250, 170, 30],\n",
    "        [220, 220, 0],\n",
    "        [107, 142, 35],\n",
    "        [152, 251, 152],\n",
    "        [0, 130, 180],\n",
    "        [220, 20, 60],\n",
    "        [255, 0, 0],\n",
    "        [0, 0, 142],\n",
    "        [0, 0, 70],\n",
    "        [0, 60, 100],\n",
    "        [0, 80, 100],\n",
    "        [0, 0, 230],\n",
    "        [119, 11, 32]])\n",
    "\n",
    "def get_pascal_labels():\n",
    "    \"\"\"Load the mapping that associates pascal classes with label colors\n",
    "    Returns:\n",
    "        np.ndarray with dimensions (21, 3)\n",
    "    \"\"\"\n",
    "    return np.asarray([[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                       [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                       [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                       [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                       [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                       [0, 64, 128]])\n",
    "\n",
    "def decode_segmap(label_mask, dataset, plot=False):\n",
    "    \"\"\"Decode segmentation class labels into a color image\n",
    "    Args:\n",
    "        label_mask (np.ndarray): an (M,N) array of integer values denoting\n",
    "          the class label at each spatial location.\n",
    "        plot (bool, optional): whether to show the resulting color image\n",
    "          in a figure.\n",
    "    Returns:\n",
    "        (np.ndarray, optional): the resulting decoded color image.\n",
    "    \"\"\"\n",
    "    if dataset == 'pascal':\n",
    "        n_classes = 21\n",
    "        label_colours = get_pascal_labels()\n",
    "    elif dataset == 'cityscapes':\n",
    "        n_classes = 19\n",
    "        label_colours = get_cityscapes_labels()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    r = label_mask.copy()\n",
    "    g = label_mask.copy()\n",
    "    b = label_mask.copy()\n",
    "    for ll in range(0, n_classes):\n",
    "        r[label_mask == ll] = label_colours[ll, 0]\n",
    "        g[label_mask == ll] = label_colours[ll, 1]\n",
    "        b[label_mask == ll] = label_colours[ll, 2]\n",
    "    rgb = np.zeros((label_mask.shape[0], label_mask.shape[1], 3))\n",
    "    rgb[:, :, 0] = r / 255.0\n",
    "    rgb[:, :, 1] = g / 255.0\n",
    "    rgb[:, :, 2] = b / 255.0\n",
    "    if plot:\n",
    "        plt.imshow(rgb)\n",
    "        plt.show()\n",
    "    else:\n",
    "        return rgb\n",
    "\n",
    "class ECELoss(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the Expected Calibration Error of a model.\n",
    "    (This isn't necessary for temperature scaling, just a cool metric).\n",
    "    The input to this loss is the logits of a model, NOT the softmax scores.\n",
    "    This divides the confidence outputs into equally-sized interval bins.\n",
    "    In each bin, we compute the confidence gap:\n",
    "    bin_gap = | avg_confidence_in_bin - accuracy_in_bin |\n",
    "    We then return a weighted average of the gaps, based on the number\n",
    "    of samples in each bin\n",
    "    Acknowledge To: https://github.com/gpleiss/temperature_scaling\n",
    "    \"\"\"\n",
    "    def __init__(self, n_bins=15, LOGIT = True):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "        self.LOGIT = LOGIT\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        n, c, h, w = logits.size()\n",
    "        logits = logits.contiguous().transpose(1, 2).transpose(2, 3).contiguous()  # n*c*h*w->n*h*c*w->n*h*w*c\n",
    "        logits = logits.view(-1, c)\n",
    "        labels = labels.contiguous().view(-1)\n",
    "        if self.LOGIT:\n",
    "            softmaxes = F.softmax(logits, dim=1)\n",
    "        else:\n",
    "            softmaxes = logits\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        correctness = predictions.eq(labels)\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = correctness[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean().float()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "        return ece\n",
    "\n",
    "def eval_uda(testfile_path,model,pretrained_model_pth,TARGET_MODALITY,Method, save_img=False):\n",
    "\n",
    "    test_list_pth = testfile_path\n",
    "\n",
    "    with open(test_list_pth) as fp:\n",
    "        rows = fp.readlines()\n",
    "    testfile_list = [row[:-1] for row in rows]\n",
    "    \n",
    "    interp = nn.Upsample(size=(256, 256), mode='bilinear', align_corners=True)\n",
    "    save_images = True\n",
    "\n",
    "    img_mean   = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
    "\n",
    "    if not osp.exists(pretrained_model_pth):\n",
    "        print('')\n",
    "    print('Evaluating model {}'.format(pretrained_model_pth))\n",
    "    load_checkpoint_for_evaluation(model,pretrained_model_pth)\n",
    "\n",
    "\n",
    "    dice_list = []\n",
    "    assd_list = []\n",
    "\n",
    "    label_all = []\n",
    "    pred_all = []\n",
    "    ece_metric = ECELoss()\n",
    "    for idx_file, fid in enumerate(testfile_list):\n",
    "        # print(fid)\n",
    "        if TARGET_MODALITY == \"CT\":\n",
    "            save_img_path = \"./save_results/MR2CT/\" + Method + \"/img/\"+str(idx_file)\n",
    "            save_gt_path = \"./save_results/MR2CT/\" + Method + \"/gt/\"+str(idx_file)\n",
    "            save_pred_path = \"./save_results/MR2CT/\" + Method + \"/pred/\"+str(idx_file)\n",
    "            save_ent_path = \"./save_results/MR2CT/\" + Method + \"/ent/\"+str(idx_file)\n",
    "        elif TARGET_MODALITY == \"MR\":\n",
    "            save_img_path = \"./save_results/MR2MR/\" + Method + \"/img/\"+str(idx_file)\n",
    "            save_gt_path = \"./save_results/MR2MR/\" + Method + \"/gt/\"+str(idx_file)\n",
    "            save_pred_path = \"./save_results/MR2MR/\" + Method + \"/pred/\"+str(idx_file)\n",
    "            save_ent_path = \"./save_results/MR2MR/\" + Method + \"/ent/\"+str(idx_file)\n",
    "        if not os.path.exists(save_img_path):\n",
    "            os.makedirs(save_img_path)\n",
    "        if not os.path.exists(save_gt_path):\n",
    "            os.makedirs(save_gt_path)\n",
    "        if not os.path.exists(save_pred_path):\n",
    "            os.makedirs(save_pred_path)\n",
    "        if not os.path.exists(save_ent_path):\n",
    "            os.makedirs(save_ent_path)\n",
    "\n",
    "\n",
    "        _npz_dict = np.load(fid)\n",
    "        data      = _npz_dict['arr_0']\n",
    "        label     = _npz_dict['arr_1']\n",
    "\n",
    "        if True:\n",
    "            data = np.flip(data, axis=0)\n",
    "            data = np.flip(data, axis=1)\n",
    "            label = np.flip(label, axis=0)\n",
    "            label = np.flip(label, axis=1)\n",
    "\n",
    "        slice_num_img = 0\n",
    "        slice_num_pred = 0\n",
    "        slice_num_gt = 0\n",
    "        slice_num_ent = 0\n",
    "        tmp_pred = np.zeros(label.shape)\n",
    "\n",
    "        tmp_pred_soft = np.zeros([5, 256, 256,label.shape[-1]])\n",
    "\n",
    "        frame_list = [kk for kk in range(data.shape[2])]\n",
    "        pred_start_time = datetime.now()\n",
    "\n",
    "        for ii in range(int(np.floor(data.shape[2] // BATCHSIZE))):\n",
    "            data_batch = np.zeros([BATCHSIZE, 3, 256, 256])\n",
    "            for idx, jj in enumerate(frame_list[ii * BATCHSIZE: (ii + 1) * BATCHSIZE]):\n",
    "                item_data = data[..., jj]\n",
    "\n",
    "                item_label = label[..., jj]\n",
    "\n",
    "                gt_save = decode_seg_map_sequence(item_label) * 255\n",
    "                # print(gt.max(),gt.min(),gt.shape)\n",
    "                gt_save = Image.fromarray(np.uint8(gt_save))\n",
    "                if save_img:\n",
    "                    gt_save.save(save_gt_path+\"/slice_{}.png\".format(slice_num_gt))\n",
    "\n",
    "\n",
    "                if TARGET_MODALITY == 'CT':\n",
    "                    item_data = np.subtract(\n",
    "                        np.multiply(np.divide(np.subtract(item_data, -2.8), np.subtract(3.2, -2.8)), 2.0),\n",
    "                        1)  # {-2.8, 3.2} need to be changed according to the metadata statistics\n",
    "                elif TARGET_MODALITY == 'MR':\n",
    "                    item_data = np.subtract(\n",
    "                        np.multiply(np.divide(np.subtract(item_data, -1.8), np.subtract(4.4, -1.8)), 2.0),\n",
    "                        1)  # {-1.8, 4.4} need to be changed according to the metadata statistics\n",
    "\n",
    "                img_save = Image.fromarray(((item_data + 1) * 127.5).astype('uint8'))\n",
    "                if save_img:\n",
    "                    img_save.save(save_img_path+\"/slice_{}.png\".format(slice_num_img))\n",
    "\n",
    "                item_data = np.expand_dims(item_data, -1)\n",
    "\n",
    "                item_data = np.tile(item_data, [1, 1, 3])\n",
    "                item_data = (item_data + 1) * 127.5\n",
    "                item_data = item_data[:, :, ::-1].copy()  # change to BGR\n",
    "                item_data -= img_mean\n",
    "                item_data = np.transpose(item_data, [2, 0, 1])\n",
    "                data_batch[idx, ...] = item_data\n",
    "\n",
    "                slice_num_img += 1\n",
    "                slice_num_gt +=1\n",
    "\n",
    "            imgs = torch.from_numpy(data_batch).cuda().float()\n",
    "            with torch.no_grad():\n",
    "                cla_feas_src,pred_b_aux, pred_b_main_soft = model(imgs)\n",
    "\n",
    "                pred_b_main_soft = interp(pred_b_main_soft)\n",
    "                pred_b_main = torch.argmax(pred_b_main_soft, dim=1)\n",
    "                pred_b_main = pred_b_main.cpu().data.numpy()\n",
    "            # print(pred_b_main_soft.shape)\n",
    "            for idx, jj in enumerate(frame_list[ii * BATCHSIZE: (ii + 1) * BATCHSIZE]):\n",
    "                tmp_pred[..., jj] = pred_b_main[idx, ...].copy()\n",
    "                tmp_pred_soft[..., jj] = pred_b_main_soft[idx, ...].cpu().data.numpy().copy()\n",
    "                pred_trg = decode_seg_map_sequence(pred_b_main[idx, ...].copy()) * 255\n",
    "                # print(gt.max(),gt.min(),gt.shape)\n",
    "                pred_trg = Image.fromarray(np.uint8(pred_trg))\n",
    "                if save_img:\n",
    "                    pred_trg.save(save_pred_path+\"/slice_{}.png\".format(slice_num_pred))\n",
    "                slice_num_pred+=1\n",
    "\n",
    "                entropy_map = _compute_entropy_map(pred_b_main_soft[idx, ...].unsqueeze(0))\n",
    "                #print(entropy_map)\n",
    "                entropy_map = entropy_map.cpu().data.numpy()\n",
    "\n",
    "                entropy_map = normalize_ent(entropy_map)\n",
    "                entropy_map = construct_color_img(entropy_map)\n",
    "                if save_img:\n",
    "                    cv2.imwrite(save_ent_path+\"/slice_{}.png\".format(slice_num_ent), entropy_map)\n",
    "                slice_num_ent +=1\n",
    "        pred_end_time = datetime.now()\n",
    "        pred_spend_time = (pred_end_time-pred_start_time).seconds\n",
    "        print('pred spend time is {} seconds'.format(pred_spend_time))\n",
    "\n",
    "        label = label.astype(int)\n",
    "        metric_start_time      = datetime.now()\n",
    "        dice, assd             = _compute_metric(tmp_pred,label)\n",
    "        metric_end_time        = datetime.now()\n",
    "        metric_spend_time      = (metric_end_time-metric_start_time).seconds\n",
    "        print('metric spend time is {} seconds'.format(metric_spend_time))\n",
    "\n",
    "        dice_list.append(dice)\n",
    "        assd_list.append(assd)\n",
    "\n",
    "        label_all.append(np.transpose(label, (2, 0, 1)))\n",
    "        pred_all.append(np.transpose(tmp_pred_soft, (3,0, 1, 2)))\n",
    "        #print(label.shape, tmp_pred_soft.shape)\n",
    "    label_all_arr = np.vstack(label_all) #N_CT * N_Class\n",
    "    pred_all_arr = np.vstack(pred_all) #N_CT * N_Class\n",
    "    #print(label_all_arr.shape,pred_all_arr.shape)\n",
    "    ece_value = ece_metric(torch.from_numpy(pred_all_arr),torch.from_numpy(label_all_arr))\n",
    "    dice_arr = np.vstack(dice_list) #N_CT * N_Class\n",
    "    assd_arr = np.vstack(assd_list) #N_CT * N_Class\n",
    "\n",
    "    dice_arr  = 100 * dice_arr.transpose()  #N_Class * N_CT\n",
    "    dice_mean = np.mean(dice_arr, axis=1) #N_Class\n",
    "    dice_std  = np.std(dice_arr, axis=1) #N_Class\n",
    "\n",
    "    print('dice arr is {}'.format(dice_arr.shape))\n",
    "    print('Dice:')\n",
    "    print('AA :%.1f(%.1f)' % (dice_mean[3], dice_std[3]))\n",
    "    print('LAC:%.1f(%.1f)' % (dice_mean[1], dice_std[1]))\n",
    "    print('LVC:%.1f(%.1f)' % (dice_mean[2], dice_std[2]))\n",
    "    print('Myo:%.1f(%.1f)' % (dice_mean[0], dice_std[0]))\n",
    "    print('Mean:%.1f' % np.mean(dice_mean))\n",
    "\n",
    "    assd_arr  = assd_arr.transpose() #N_Class * N_CT\n",
    "    assd_mean = np.mean(assd_arr, axis=1)\n",
    "    assd_std  = np.std(assd_arr, axis=1)\n",
    "\n",
    "    print('ASSD:')\n",
    "    print('AA :%.1f(%.1f)' % (assd_mean[3], assd_std[3]))\n",
    "    print('LAC:%.1f(%.1f)' % (assd_mean[1], assd_std[1]))\n",
    "    print('LVC:%.1f(%.1f)' % (assd_mean[2], assd_std[2]))\n",
    "    print('Myo:%.1f(%.1f)' % (assd_mean[0], assd_std[0]))\n",
    "    print('Mean:%.1f' % np.mean(assd_mean))\n",
    "    print(\"Ece value:\", ece_value)\n",
    "\n",
    "    return dice_mean,dice_std,assd_mean,assd_std,ece_value\n",
    "\n",
    "def load_checkpoint_for_evaluation(model, checkpoint):\n",
    "    saved_state_dict = torch.load(checkpoint,map_location='cpu', weights_only=True)\n",
    "    model.load_state_dict(saved_state_dict)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.enabled = True\n",
    "\n",
    "def _compute_metric(pred,target):\n",
    "\n",
    "    pred = pred.astype(int)\n",
    "    target = target.astype(int)\n",
    "    dice_list  = []\n",
    "    assd_list  = []\n",
    "    pred_each_class_number = []\n",
    "    true_each_class_number = []\n",
    "\n",
    "\n",
    "    for c in range(1,NUMCLASS):\n",
    "        y_true    = target.copy()\n",
    "        test_pred = pred.copy()\n",
    "        test_pred[test_pred != c] = 0\n",
    "        test_pred[test_pred == c] = 1\n",
    "        y_true[y_true != c] = 0\n",
    "        y_true[y_true == c] = 1\n",
    "        pred_each_class_number.append(np.sum(test_pred))\n",
    "        true_each_class_number.append(np.sum(y_true))\n",
    "\n",
    "    for c in range(1, NUMCLASS):\n",
    "        test_pred = pred.copy()\n",
    "        test_pred[test_pred != c] = 0\n",
    "\n",
    "        test_gt = target.copy()\n",
    "        test_gt[test_gt != c] = 0\n",
    "\n",
    "        dice = dc(test_pred, test_gt)\n",
    "\n",
    "        try:\n",
    "            assd_metric = assd(test_pred, test_gt)\n",
    "        except:\n",
    "            print('assd error')\n",
    "            assd_metric = 1\n",
    "\n",
    "        dice_list.append(dice)\n",
    "        assd_list.append(assd_metric)\n",
    "\n",
    "    return np.array(dice_list),np.array(assd_list)\n",
    "\n",
    "def _compute_entropy_map(pred):\n",
    "\n",
    "    '''\n",
    "    pred: n*c*h*w\n",
    "    '''\n",
    "    n,c,h,w = pred.shape\n",
    "    # print(pred.shape)\n",
    "    pred = torch.softmax(pred,dim=1)\n",
    "    self_information_map =  -torch.mul(pred, torch.log2(pred + 1e-30)) / np.log2(c)\n",
    "    entropy_map = torch.sum(self_information_map,dim=1) # n*h*w\n",
    "\n",
    "    return entropy_map.squeeze()\n",
    "\n",
    "def construct_color_img(prob_per_slice):\n",
    "    shape = prob_per_slice.shape\n",
    "    # print(shape)\n",
    "    img = np.zeros((shape[0], shape[1], 3), dtype=np.uint8)\n",
    "    img[:, :, 0] = prob_per_slice * 255\n",
    "    img[:, :, 1] = prob_per_slice * 255\n",
    "    img[:, :, 2] = prob_per_slice * 255\n",
    "\n",
    "    im_color = cv2.applyColorMap(img, cv2.COLORMAP_JET)\n",
    "    return im_color\n",
    "\n",
    "\n",
    "def normalize_ent(ent):\n",
    "    '''\n",
    "    Normalizate ent to 0 - 1\n",
    "    :param ent:\n",
    "    :return:\n",
    "    '''\n",
    "    min = np.amin(ent)\n",
    "    max = np.amin(ent)\n",
    "    return (ent - min) / 0.4\n",
    "    # return (ent - min) / (max-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec5c9cb2-19ab-4709-ba94-11ac2a7e3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE     = 32\n",
    "data_size     = [256, 256, 1]\n",
    "label_size    = [256, 256, 1]\n",
    "NUMCLASS      = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee4f15c-311e-4e07-8e22-36920fea2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.deeplabv2 import get_deeplab_v2\n",
    "\n",
    "model = get_deeplab_v2(num_classes=5, multi_level=True)\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7465b53-8a09-4cf9-bfa0-8511590f883f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model snapshot/UDA_DAP_MR2CT_exp10_naive_thresh/model_3800.pth\n",
      "pred spend time is 52 seconds\n",
      "metric spend time is 63 seconds\n",
      "pred spend time is 8 seconds\n",
      "metric spend time is 62 seconds\n",
      "pred spend time is 8 seconds\n",
      "metric spend time is 62 seconds\n",
      "pred spend time is 8 seconds\n",
      "metric spend time is 62 seconds\n",
      "dice arr is (4, 4)\n",
      "Dice:\n",
      "AA :70.4(6.5)\n",
      "LAC:72.5(5.4)\n",
      "LVC:70.7(10.9)\n",
      "Myo:54.6(5.9)\n",
      "Mean:67.1\n",
      "ASSD:\n",
      "AA :22.0(2.3)\n",
      "LAC:18.1(7.5)\n",
      "LVC:18.1(13.3)\n",
      "Myo:11.3(5.9)\n",
      "Mean:17.4\n",
      "Ece value: tensor([0.0112])\n",
      "(array([54.57903165, 72.48712997, 70.72970003, 70.40462463]), array([ 5.8739156 ,  5.35309216, 10.9269098 ,  6.49931428]), array([11.34944324, 18.0944169 , 18.09150064, 21.97894574]), array([ 5.913315  ,  7.52873931, 13.33021022,  2.2552423 ]), tensor([0.0112]))\n"
     ]
    }
   ],
   "source": [
    "print(eval_uda(testfile_path='data/datalist/test_ct.txt', model=model,  pretrained_model_pth='snapshot/UDA_DAP_MR2CT_exp10_naive_thresh/model_3800.pth', TARGET_MODALITY='CT', Method='uda_dap_MR2CT_exp10_naive_thresh', save_img=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b56154-cb12-4b9f-80eb-07f767a7241d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326daeb-1a6c-4d23-b267-214b4ad560a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
